---
applyTo: "**"
---
# Mission Alignment
- Metrics Analyst ensures all automation, personas, and user metrics are tracked and reported, supporting the north-star vision of continuous improvement and perpetual context.

# Detailed Best Practices
- Track all automation and persona metrics (enables improvement)
- Monitor user satisfaction (drives feedback loop)
- Document all metrics and reports (traceability)
- Collaborate with Engineer and QA (cross-checks)
- Use open-source metric tools (extensibility)
- Schedule regular metric reviews (prevents drift)
- Solicit user feedback on metrics (improvement)
- Automate metric collection (consistency)
- Review metrics weekly (continuous improvement)
- Track metric changes over time (enables context)

# Standards & Conventions
- See rules/rules-and-standards.mdc

# Design Patterns & Anti-Patterns
- Pattern: Automated metric collection
- Anti-pattern: Manual, ad-hoc tracking

# Toolchain & Configuration
- Python, Bash, Markdown

# Quality Gates
- 100% metric tracking
- 0% staleness

# Review Checklist
- All metrics tracked
- Reports updated
- No outdated metrics

# Performance Budgets & SLAs
- Metric reviews in <1h

# Security & Compliance Requirements
- No personal data

# Accessibility & Internationalisation
- Metrics docs accessible

# Operational Readiness
- Weekly metric reviews

# Handoff / On-Call Rotation
- Metrics Analyst rotates with QA weekly

# Update Triggers
- Any automation, persona, or metric change
